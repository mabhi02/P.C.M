{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Correlation Manifold (PCM) - Training\n",
    "\n",
    "This notebook trains the PCM model for AI-generated image detection. It integrates all components of the architecture:\n",
    "\n",
    "1. Feature Extraction Network\n",
    "2. Manifold Learning Module\n",
    "3. Topological Analysis\n",
    "4. Classification Network\n",
    "\n",
    "The model is trained on a dataset of natural and AI-generated images to learn the distinctive phase correlation patterns that differentiate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our custom modules\n",
    "from utils.feature_extraction import FeatureExtractionNetwork, PhaseCorrelationTensorComputation, ImagePreprocessor\n",
    "from utils.manifold_learning import ManifoldLearningModule\n",
    "from utils.topological_analysis import TopologicalFeatureExtraction\n",
    "from utils.classification import ClassificationNetwork\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Definition\n",
    "\n",
    "We'll create a dataset class that loads natural and AI-generated images. \n",
    "For real training, you should replace this with your actual dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        \n",
    "        # Define transforms using standard torchvision transformations\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_files[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            # Open image with PIL and convert to RGB\n",
    "            with Image.open(image_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img_tensor = self.transform(img)\n",
    "                return img_tensor, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # Return a placeholder tensor and the label\n",
    "            return torch.ones(3, 256, 256), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "Let's create our dataset. If you have real data, specify the paths to your natural and AI-generated image directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from train.csv file\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_path = r'C:\\Users\\mabhi\\.cache\\kagglehub\\datasets\\alessandrasala79\\ai-vs-human-generated-dataset\\versions\\4\\train.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"CSV columns: {df.columns.tolist()}\")\n",
    "print(f\"First few rows of the CSV:\\n{df.head()}\")\n",
    "\n",
    "# Get the base path for the images\n",
    "base_path = os.path.dirname(csv_path)\n",
    "\n",
    "# Parse file paths and labels from CSV\n",
    "all_files = []\n",
    "labels = []\n",
    "\n",
    "# Extract file paths and labels from the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    file_path = os.path.join(base_path, row['file_name'])\n",
    "    label = int(row['label'])  # Assuming 0 = Natural, 1 = AI\n",
    "    \n",
    "    # Verify that the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        all_files.append(file_path)\n",
    "        labels.append(label)\n",
    "    else:\n",
    "        print(f\"Warning: File not found: {file_path}\")\n",
    "\n",
    "print(f\"Total images found: {len(all_files)}\")\n",
    "print(f\"Natural images: {labels.count(0)}\")\n",
    "print(f\"AI-generated images: {labels.count(1)}\")\n",
    "\n",
    "# Create the dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        \n",
    "        # Define transforms using standard torchvision transformations\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_files[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            # Open image with PIL and convert to RGB\n",
    "            with Image.open(image_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img_tensor = self.transform(img)\n",
    "                return img_tensor, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # Return a placeholder tensor and the label\n",
    "            return torch.ones(3, 256, 256), label\n",
    "\n",
    "# Create the dataset\n",
    "dataset = CustomImageDataset(all_files, labels)\n",
    "\n",
    "# Split the dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders with smaller batch size\n",
    "batch_size = 2  # Reduced from 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Check a batch of data\n",
    "try:\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Labels: {labels}\")\n",
    "    \n",
    "    # Visualize a few images\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(min(4, len(images))):\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Label: {'Natural' if labels[i] == 0 else 'AI'}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading batch: {e}\")\n",
    "    print(\"This might indicate issues with image loading or dataset structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model Components\n",
    "\n",
    "Now we'll initialize all components of the PCM architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model components\n",
    "feature_network = FeatureExtractionNetwork().to(device)\n",
    "tensor_computer = PhaseCorrelationTensorComputation().to(device)\n",
    "manifold_module = ManifoldLearningModule().to(device)\n",
    "\n",
    "# For topological analysis, we need to create point clouds from manifold features\n",
    "# This is a simplified version for training\n",
    "class PointCloudGenerator(nn.Module):\n",
    "    def __init__(self, num_points=100, noise_scale=0.1):\n",
    "        super().__init__()\n",
    "        self.num_points = num_points\n",
    "        self.noise_scale = noise_scale\n",
    "    \n",
    "    def forward(self, features):\n",
    "        batch_size, feature_dim = features.size()\n",
    "        \n",
    "        # Expand features to create a point cloud\n",
    "        point_cloud = features.unsqueeze(1).expand(-1, self.num_points, -1)\n",
    "        \n",
    "        # Add noise for a more interesting point cloud\n",
    "        noise = torch.randn(batch_size, self.num_points, feature_dim, device=features.device) * self.noise_scale\n",
    "        point_cloud = point_cloud + noise\n",
    "        \n",
    "        return point_cloud\n",
    "\n",
    "point_cloud_generator = PointCloudGenerator().to(device)\n",
    "topo_module = TopologicalFeatureExtraction().to(device)\n",
    "classifier = ClassificationNetwork().to(device)\n",
    "\n",
    "# Print model sizes\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Feature Extraction Network: {count_parameters(feature_network):,} parameters\")\n",
    "print(f\"Phase Correlation Tensor Computation: {count_parameters(tensor_computer):,} parameters\")\n",
    "print(f\"Manifold Learning Module: {count_parameters(manifold_module):,} parameters\")\n",
    "print(f\"Topological Feature Extraction: {count_parameters(topo_module):,} parameters\")\n",
    "print(f\"Classification Network: {count_parameters(classifier):,} parameters\")\n",
    "print(f\"Total: {count_parameters(feature_network) + count_parameters(tensor_computer) + count_parameters(manifold_module) + count_parameters(topo_module) + count_parameters(classifier):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Functions\n",
    "\n",
    "We'll define functions for training and evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "classification_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# VAE loss for manifold learning\n",
    "def vae_loss(x_recon, x, mu, logvar, beta=1.0):\n",
    "    # Reconstruction loss\n",
    "    recon_loss = F.mse_loss(x_recon, x, reduction='sum') / x.size(0)\n",
    "    \n",
    "    # KL divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "    \n",
    "    return recon_loss + beta * kl_loss\n",
    "\n",
    "# Define optimizers\n",
    "# We'll use separate optimizers for each component\n",
    "feature_optimizer = optim.Adam(list(feature_network.parameters()) + \n",
    "                              list(tensor_computer.parameters()), lr=1e-4)\n",
    "manifold_optimizer = optim.Adam(manifold_module.parameters(), lr=1e-4)\n",
    "topo_optimizer = optim.Adam(topo_module.parameters(), lr=1e-4)\n",
    "classifier_optimizer = optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "\n",
    "# Learning rate schedulers\n",
    "feature_scheduler = optim.lr_scheduler.ReduceLROnPlateau(feature_optimizer, mode='min', factor=0.5, patience=5)\n",
    "manifold_scheduler = optim.lr_scheduler.ReduceLROnPlateau(manifold_optimizer, mode='min', factor=0.5, patience=5)\n",
    "topo_scheduler = optim.lr_scheduler.ReduceLROnPlateau(topo_optimizer, mode='min', factor=0.5, patience=5)\n",
    "classifier_scheduler = optim.lr_scheduler.ReduceLROnPlateau(classifier_optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Now we'll define the main training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, epoch):\n",
    "    # Set models to training mode\n",
    "    feature_network.train()\n",
    "    tensor_computer.train()\n",
    "    manifold_module.train()\n",
    "    topo_module.train()\n",
    "    classifier.train()\n",
    "    \n",
    "    # Initialize metrics\n",
    "    total_loss = 0\n",
    "    total_feature_loss = 0\n",
    "    total_manifold_loss = 0\n",
    "    total_topo_loss = 0\n",
    "    total_classifier_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Training loop\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        # Move data to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Reset gradients\n",
    "        feature_optimizer.zero_grad()\n",
    "        manifold_optimizer.zero_grad()\n",
    "        topo_optimizer.zero_grad()\n",
    "        classifier_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass through feature extraction\n",
    "        features, _ = feature_network(images)\n",
    "        phase_tensor = tensor_computer(features)\n",
    "        \n",
    "        # Forward pass through manifold learning\n",
    "        manifold_features, (mu, logvar, z) = manifold_module(phase_tensor)\n",
    "        \n",
    "        # Reconstruct for VAE loss\n",
    "        recon_tensor = manifold_module.vae.decode(z)\n",
    "        manifold_loss = manifold_module.get_loss(phase_tensor, recon_tensor, mu, logvar)[0]\n",
    "        \n",
    "        # Generate point cloud for topological analysis\n",
    "        point_cloud = point_cloud_generator(manifold_features)\n",
    "        \n",
    "        # Forward pass through topological analysis\n",
    "        topo_features, _ = topo_module(point_cloud)\n",
    "        \n",
    "        # Forward pass through classifier\n",
    "        logits, probs, uncertainty = classifier(manifold_features, topo_features)\n",
    "        \n",
    "        # Compute classification loss\n",
    "        classifier_loss = classification_criterion(logits, labels)\n",
    "        \n",
    "        # Total loss (with weights)\n",
    "        feature_loss = F.mse_loss(features, features.detach())  # Dummy loss for feature extraction\n",
    "        topo_loss = F.mse_loss(topo_features, topo_features.detach())  # Dummy loss for topological analysis\n",
    "        \n",
    "        # Backward pass - we'll do this separately for each component\n",
    "        # This is a simplified training approach\n",
    "        \n",
    "        # 1. Train feature extraction\n",
    "        feature_loss.backward(retain_graph=True)\n",
    "        feature_optimizer.step()\n",
    "        \n",
    "        # 2. Train manifold learning\n",
    "        manifold_optimizer.zero_grad()\n",
    "        manifold_loss.backward(retain_graph=True)\n",
    "        manifold_optimizer.step()\n",
    "        \n",
    "        # 3. Train topological analysis\n",
    "        topo_optimizer.zero_grad()\n",
    "        topo_loss.backward(retain_graph=True)\n",
    "        topo_optimizer.step()\n",
    "        \n",
    "        # 4. Train classifier\n",
    "        classifier_optimizer.zero_grad()\n",
    "        classifier_loss.backward()\n",
    "        classifier_optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        total_feature_loss += feature_loss.item()\n",
    "        total_manifold_loss += manifold_loss.item()\n",
    "        total_topo_loss += topo_loss.item()\n",
    "        total_classifier_loss += classifier_loss.item()\n",
    "        total_loss += (feature_loss.item() + manifold_loss.item() + \n",
    "                      topo_loss.item() + classifier_loss.item())\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += pred.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': total_loss / (batch_idx + 1),\n",
    "            'acc': 100. * correct / total\n",
    "        })\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_feature_loss = total_feature_loss / len(train_loader)\n",
    "    avg_manifold_loss = total_manifold_loss / len(train_loader)\n",
    "    avg_topo_loss = total_topo_loss / len(train_loader)\n",
    "    avg_classifier_loss = total_classifier_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'feature_loss': avg_feature_loss,\n",
    "        'manifold_loss': avg_manifold_loss,\n",
    "        'topo_loss': avg_topo_loss,\n",
    "        'classifier_loss': avg_classifier_loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "def validate(val_loader):\n",
    "    # Set models to evaluation mode\n",
    "    feature_network.eval()\n",
    "    tensor_computer.eval()\n",
    "    manifold_module.eval()\n",
    "    topo_module.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    # Initialize metrics\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Store predictions and true labels for confusion matrix\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    all_uncertainty = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            features, _ = feature_network(images)\n",
    "            phase_tensor = tensor_computer(features)\n",
    "            manifold_features, _ = manifold_module(phase_tensor)\n",
    "            point_cloud = point_cloud_generator(manifold_features)\n",
    "            topo_features, _ = topo_module(point_cloud)\n",
    "            logits, probs, uncertainty = classifier(manifold_features, topo_features)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = classification_criterion(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            # Store for metrics\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_uncertainty.append(uncertainty.cpu())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Concatenate predictions and labels\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_probs = torch.cat(all_probs)\n",
    "    all_uncertainty = torch.cat(all_uncertainty)\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs,\n",
    "        'uncertainty': all_uncertainty\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop\n",
    "\n",
    "Now we'll run the main training loop for multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "best_val_accuracy = 0\n",
    "\n",
    "# Metrics tracking\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Train for one epoch\n",
    "    train_metrics = train_epoch(train_loader, epoch)\n",
    "    train_losses.append(train_metrics['loss'])\n",
    "    train_accuracies.append(train_metrics['accuracy'])\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = validate(val_loader)\n",
    "    val_losses.append(val_metrics['loss'])\n",
    "    val_accuracies.append(val_metrics['accuracy'])\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Epoch {epoch}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_metrics['loss']:.4f}, Train Acc: {train_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_metrics['loss']:.4f}, Val Acc: {val_metrics['accuracy']:.2f}%\")\n",
    "    \n",
    "    # Update learning rate schedulers\n",
    "    feature_scheduler.step(val_metrics['loss'])\n",
    "    manifold_scheduler.step(val_metrics['loss'])\n",
    "    topo_scheduler.step(val_metrics['loss'])\n",
    "    classifier_scheduler.step(val_metrics['loss'])\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['accuracy'] > best_val_accuracy:\n",
    "        best_val_accuracy = val_metrics['accuracy']\n",
    "        print(f\"  New best model with accuracy: {best_val_accuracy:.2f}%\")\n",
    "        \n",
    "        # Save each component separately\n",
    "        torch.save(feature_network.state_dict(), 'models/feature_network.pth')\n",
    "        torch.save(tensor_computer.state_dict(), 'models/tensor_computer.pth')\n",
    "        torch.save(manifold_module.state_dict(), 'models/manifold_module.pth')\n",
    "        torch.save(topo_module.state_dict(), 'models/topo_module.pth')\n",
    "        torch.save(classifier.state_dict(), 'models/classifier.pth')\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Results\n",
    "\n",
    "Let's visualize the training process by plotting the loss and accuracy curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, 'b-', label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, 'b-', label='Train Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, 'r-', label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/training_curves.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "Now let's analyze the model performance in more detail, including a confusion matrix and uncertainty analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "feature_network.load_state_dict(torch.load('models/feature_network.pth'))\n",
    "tensor_computer.load_state_dict(torch.load('models/tensor_computer.pth'))\n",
    "manifold_module.load_state_dict(torch.load('models/manifold_module.pth'))\n",
    "topo_module.load_state_dict(torch.load('models/topo_module.pth'))\n",
    "classifier.load_state_dict(torch.load('models/classifier.pth'))\n",
    "\n",
    "# Get validation metrics\n",
    "val_metrics = validate(val_loader)\n",
    "\n",
    "# Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "y_true = val_metrics['labels'].numpy()\n",
    "y_pred = val_metrics['predictions'].numpy()\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Natural', 'AI-Generated'],\n",
    "            yticklabels=['Natural', 'AI-Generated'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('results/confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Natural', 'AI-Generated']))\n",
    "\n",
    "# Analyze uncertainty\n",
    "uncertainty = val_metrics['uncertainty'].numpy()\n",
    "probabilities = val_metrics['probabilities'].numpy()\n",
    "\n",
    "# Plot uncertainty distribution for correct and incorrect predictions\n",
    "correct_mask = y_pred == y_true\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(uncertainty[correct_mask], bins=20, alpha=0.7, label='Correct Predictions', color='green')\n",
    "plt.hist(uncertainty[~correct_mask], bins=20, alpha=0.7, label='Incorrect Predictions', color='red')\n",
    "plt.xlabel('Uncertainty')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Uncertainty Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('results/uncertainty_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Use probabilities for AI-generated class\n",
    "ai_probs = probabilities[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_true, ai_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('results/roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Topological Features\n",
    "\n",
    "Let's visualize the topological features extracted from a few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.topological_analysis import visualize_persistence_diagram, visualize_betti_curves, visualize_persistence_image\n",
    "\n",
    "# Get a few sample images\n",
    "sample_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "sample_images, sample_labels = next(iter(sample_loader))\n",
    "sample_images = sample_images.to(device)\n",
    "\n",
    "# Process images through the pipeline\n",
    "with torch.no_grad():\n",
    "    features, _ = feature_network(sample_images)\n",
    "    phase_tensor = tensor_computer(features)\n",
    "    manifold_features, _ = manifold_module(phase_tensor)\n",
    "    point_cloud = point_cloud_generator(manifold_features)\n",
    "    topo_features, topo_data = topo_module(point_cloud)\n",
    "    logits, probs, uncertainty = classifier(manifold_features, topo_features)\n",
    "\n",
    "# Get predictions\n",
    "predictions = logits.argmax(dim=1).cpu()\n",
    "\n",
    "# Display images and predictions\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    img = sample_images[i].cpu().permute(1, 2, 0).numpy()\n",
    "    plt.imshow(img)\n",
    "    true_label = 'Natural' if sample_labels[i] == 0 else 'AI-Generated'\n",
    "    pred_label = 'Natural' if predictions[i] == 0 else 'AI-Generated'\n",
    "    plt.title(f\"True: {true_label}, Pred: {pred_label}\\nProb: {probs[i][predictions[i]]:.2f}, Uncert: {uncertainty[i]:.2f}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sample_predictions.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualize persistence diagrams for one natural and one AI image\n",
    "natural_idx = (sample_labels == 0).nonzero()[0].item()\n",
    "ai_idx = (sample_labels == 1).nonzero()[0].item()\n",
    "\n",
    "# Get persistence diagrams\n",
    "persistence_diagrams = topo_data['persistence_diagrams']\n",
    "betti_curves = topo_data['betti_curves']\n",
    "persistence_images = topo_data['persistence_images']\n",
    "\n",
    "# Plot persistence diagrams\n",
    "plt.figure(figsize=(15, 10))\n",
    "for dim in range(min(3, persistence_diagrams.size(1))):\n",
    "    # Natural image\n",
    "    plt.subplot(2, 3, dim+1)\n",
    "    diag = persistence_diagrams[natural_idx]\n",
    "    visualize_persistence_diagram(diag, dimension=dim, title=f\"Natural Image - Dim {dim}\")\n",
    "    \n",
    "    # AI image\n",
    "    plt.subplot(2, 3, dim+4)\n",
    "    diag = persistence_diagrams[ai_idx]\n",
    "    visualize_persistence_diagram(diag, dimension=dim, title=f\"AI Image - Dim {dim}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/persistence_diagrams.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot Betti curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "visualize_betti_curves(betti_curves[natural_idx], title=\"Betti Curves - Natural Image\")\n",
    "plt.subplot(1, 2, 2)\n",
    "visualize_betti_curves(betti_curves[ai_idx], title=\"Betti Curves - AI Image\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/betti_curves.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot persistence images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for dim in range(min(2, persistence_images.size(1))):\n",
    "    plt.subplot(2, 2, dim+1)\n",
    "    visualize_persistence_image(persistence_images[natural_idx], dimension=dim, title=f\"Natural Image - Dim {dim}\")\n",
    "    \n",
    "    plt.subplot(2, 2, dim+3)\n",
    "    visualize_persistence_image(persistence_images[ai_idx], dimension=dim, title=f\"AI Image - Dim {dim}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/persistence_images.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on New Images\n",
    "\n",
    "Now let's create a function to test the model on new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    \"\"\"Test the model on a new image\"\"\"\n",
    "    # Load image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Preprocess\n",
    "    preprocessor = ImagePreprocessor(target_size=(256, 256))\n",
    "    processed_img = preprocessor.process(img)\n",
    "    \n",
    "    # Add batch dimension\n",
    "    processed_img = processed_img.unsqueeze(0).to(device)\n",
    "    \n",
    "    # Set models to evaluation mode\n",
    "    feature_network.eval()\n",
    "    tensor_computer.eval()\n",
    "    manifold_module.eval()\n",
    "    topo_module.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    # Process image\n",
    "    with torch.no_grad():\n",
    "        features, branch_outputs = feature_network(processed_img)\n",
    "        phase_tensor = tensor_computer(features)\n",
    "        manifold_features, _ = manifold_module(phase_tensor)\n",
    "        point_cloud = point_cloud_generator(manifold_features)\n",
    "        topo_features, topo_data = topo_module(point_cloud)\n",
    "        logits, probs, uncertainty = classifier(manifold_features, topo_features)\n",
    "    \n",
    "    # Get prediction\n",
    "    prediction = logits.argmax(dim=1).item()\n",
    "    probability = probs[0, prediction].item()\n",
    "    uncertainty_value = uncertainty.item()\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.array(img))\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Visualize branch outputs\n",
    "    spatial_features = branch_outputs[0][0, 0].cpu().numpy()\n",
    "    fourier_features = branch_outputs[1][0, 0].cpu().numpy()\n",
    "    multiscale_features = branch_outputs[2][0, 0].cpu().numpy()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    result_label = 'Natural' if prediction == 0 else 'AI-Generated'\n",
    "    plt.text(0.5, 0.5, f\"Prediction: {result_label}\\nProbability: {probability:.4f}\\nUncertainty: {uncertainty_value:.4f}\", \n",
    "             horizontalalignment='center', verticalalignment='center', fontsize=14,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return detailed results\n",
    "    return {\n",
    "        'prediction': result_label,\n",
    "        'probability': probability,\n",
    "        'uncertainty': uncertainty_value,\n",
    "        'spatial_features': spatial_features,\n",
    "        'fourier_features': fourier_features,\n",
    "        'multiscale_features': multiscale_features,\n",
    "        'phase_tensor': phase_tensor.cpu().numpy(),\n",
    "        'manifold_features': manifold_features.cpu().numpy(),\n",
    "        'topo_features': topo_features.cpu().numpy(),\n",
    "        'persistence_diagrams': topo_data['persistence_diagrams'].cpu().numpy(),\n",
    "        'betti_curves': topo_data['betti_curves'].cpu().numpy(),\n",
    "        'persistence_images': topo_data['persistence_images'].cpu().numpy()\n",
    "    }\n",
    "\n",
    "# Test on a new image (if available)\n",
    "test_image_path = 'data/natural/natural_000.png'  # Change this to your test image\n",
    "if os.path.exists(test_image_path):\n",
    "    result = predict_image(test_image_path)\n",
    "    print(f\"Prediction: {result['prediction']}\")\n",
    "    print(f\"Probability: {result['probability']:.4f}\")\n",
    "    print(f\"Uncertainty: {result['uncertainty']:.4f}\")\n",
    "else:\n",
    "    print(f\"Test image not found: {test_image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model for Deployment\n",
    "\n",
    "Let's save the entire model architecture for deployment in the app.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entire pipeline components\n",
    "pipeline_components = {\n",
    "    'feature_network': feature_network.state_dict(),\n",
    "    'tensor_computer': tensor_computer.state_dict(),\n",
    "    'manifold_module': manifold_module.state_dict(),\n",
    "    'topo_module': topo_module.state_dict(),\n",
    "    'classifier': classifier.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(pipeline_components, 'models/pcm_detector_pipeline.pth')\n",
    "print(\"Pipeline saved to 'models/pcm_detector_pipeline.pth'\")\n",
    "\n",
    "# Save model configuration\n",
    "import json\n",
    "\n",
    "model_config = {\n",
    "    'feature_dim': 64,\n",
    "    'manifold_dim': 32,\n",
    "    'topo_dim': 32,\n",
    "    'input_size': [256, 256],\n",
    "    'date_trained': str(torch.datetime.datetime.now()),\n",
    "    'best_accuracy': float(best_val_accuracy)\n",
    "}\n",
    "\n",
    "with open('models/pcm_detector_config.json', 'w') as f:\n",
    "    json.dump(model_config, f, indent=2)\n",
    "\n",
    "print(\"Model configuration saved to 'models/pcm_detector_config.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have successfully trained a complete Phase Correlation Manifold (PCM) model for AI-generated image detection. The model integrates multiple components:\n",
    "\n",
    "1. Feature extraction with three specialized branches\n",
    "2. Phase correlation tensor computation\n",
    "3. Manifold learning for dimensionality reduction\n",
    "4. Topological analysis of the manifold structure\n",
    "5. Classification with uncertainty estimation\n",
    "\n",
    "The trained model achieves good performance on the validation set and can be used to detect AI-generated images with high accuracy. The topological features provide an interpretable way to understand the differences between natural and AI-generated images.\n",
    "\n",
    "The next step is to deploy this model in the app.ipynb notebook for interactive use with new images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
